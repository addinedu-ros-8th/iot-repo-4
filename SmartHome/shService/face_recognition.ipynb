{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dlib \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from torchsummary import summary\n",
    "import sys\n",
    "sys.path.append(\"./insightface/recognition/arcface_torch\")\n",
    "\n",
    "from backbones.iresnet import iresnet50\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote = mysql.connector.connect(\n",
    "    host = \"database-1.c7iiuw4kenou.ap-northeast-2.rds.amazonaws.com\",\n",
    "    user = \"chillHome\",\n",
    "    password = \"addinedu1!\",\n",
    "    database = \"chillHome\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cursor = remote.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACIAL_LANDMARKS_68_IDXS = OrderedDict([\n",
    "\t(\"mouth\", (48, 68)),\n",
    "\t(\"inner_mouth\", (60, 68)),\n",
    "\t(\"right_eyebrow\", (17, 22)),\n",
    "\t(\"left_eyebrow\", (22, 27)),\n",
    "\t(\"right_eye\", (36, 42)),\n",
    "\t(\"left_eye\", (42, 48)),\n",
    "\t(\"nose\", (27, 36)),\n",
    "\t(\"jaw\", (0, 17))\n",
    "])\n",
    "\n",
    "FACIAL_LANDMARKS_5_IDXS = OrderedDict([\n",
    "\t(\"right_eye\", (2, 3)),\n",
    "\t(\"left_eye\", (0, 1)),\n",
    "\t(\"nose\", (4))\n",
    "])\n",
    "\n",
    "FACIAL_LANDMARKS_IDXS = FACIAL_LANDMARKS_68_IDXS\n",
    "\n",
    "def rect_to_bb(rect):\n",
    "\tx = rect.left()\n",
    "\ty = rect.top()\n",
    "\tw = rect.right() - x\n",
    "\th = rect.bottom() - y\n",
    "\treturn (x, y, w, h)\n",
    "\n",
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "\tcoords = np.zeros((shape.num_parts, 2), dtype=dtype)\n",
    "\n",
    "\tfor i in range(0, shape.num_parts):\n",
    "\t\tcoords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "\n",
    "\treturn coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceAligner:\n",
    "    def __init__(self, predictor, desiredLeftEye=(0.35, 0.35),\n",
    "        desiredFaceWidth=256, desiredFaceHeight=None):\n",
    "\n",
    "        self.predictor = predictor\n",
    "        self.desiredLeftEye = desiredLeftEye\n",
    "        self.desiredFaceWidth = desiredFaceWidth\n",
    "        self.desiredFaceHeight = desiredFaceHeight\n",
    "\n",
    "\n",
    "        if self.desiredFaceHeight is None:\n",
    "            self.desiredFaceHeight = self.desiredFaceWidth\n",
    "\n",
    "    def align(self, image, gray, rect):\n",
    "        shape = self.predictor(gray, rect)\n",
    "        shape = shape_to_np(shape)\n",
    "\n",
    "        if (len(shape)==68):\n",
    "            (lStart, lEnd) = FACIAL_LANDMARKS_68_IDXS[\"left_eye\"]\n",
    "            (rStart, rEnd) = FACIAL_LANDMARKS_68_IDXS[\"right_eye\"]\n",
    "        else:\n",
    "            (lStart, lEnd) = FACIAL_LANDMARKS_5_IDXS[\"left_eye\"]\n",
    "            (rStart, rEnd) = FACIAL_LANDMARKS_5_IDXS[\"right_eye\"]\n",
    "            \n",
    "        leftEyePts = shape[lStart:lEnd]\n",
    "        rightEyePts = shape[rStart:rEnd]\n",
    "\n",
    "        leftEyeCenter = leftEyePts.mean(axis=0).astype(\"int\")\n",
    "        rightEyeCenter = rightEyePts.mean(axis=0).astype(\"int\")\n",
    "\n",
    "        dY = rightEyeCenter[1] - leftEyeCenter[1]\n",
    "        dX = rightEyeCenter[0] - leftEyeCenter[0]\n",
    "        angle = np.degrees(np.arctan2(dY, dX)) - 180\n",
    "\n",
    "        desiredRightEyeX = 1.0 - self.desiredLeftEye[0]\n",
    "\n",
    "        dist = np.sqrt((dX ** 2) + (dY ** 2))\n",
    "        desiredDist = (desiredRightEyeX - self.desiredLeftEye[0])\n",
    "        desiredDist *= self.desiredFaceWidth\n",
    "        scale = desiredDist / dist\n",
    "\n",
    "        eyesCenter = (int((leftEyeCenter[0] + rightEyeCenter[0]) // 2),\n",
    "            int((leftEyeCenter[1] + rightEyeCenter[1]) // 2))\n",
    "\n",
    "        M = cv2.getRotationMatrix2D(eyesCenter, angle, scale)\n",
    "\n",
    "        tX = self.desiredFaceWidth * 0.5\n",
    "        tY = self.desiredFaceHeight * self.desiredLeftEye[1]\n",
    "        M[0, 2] += (tX - eyesCenter[0])\n",
    "        M[1, 2] += (tY - eyesCenter[1])\n",
    "\n",
    "        (w, h) = (self.desiredFaceWidth, self.desiredFaceHeight)\n",
    "        output = cv2.warpAffine(image, M, (w, h),\n",
    "            flags=cv2.INTER_CUBIC)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_file = \"./model/shape_predictor_68_face_landmarks.dat\"\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "shape_predictor = dlib.shape_predictor(predictor_file)\n",
    "fa = FaceAligner(shape_predictor, desiredFaceWidth=112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_norm(x, axis=1):\n",
    "    norm = np.linalg.norm(x, axis=axis, keepdims=True)\n",
    "    return x / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_embedding(model, img, dsize=112, device='cuda'):\n",
    "    img = cv2.resize(img, (dsize,dsize))\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    img = torch.from_numpy(img).unsqueeze(0).float()\n",
    "    img.div_(255).sub_(0.5).div_(0.5)\n",
    "    img = img.to(device)\n",
    "    embed = model(img).detach().cpu().numpy()\n",
    "    return l2_norm(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded!\n"
     ]
    }
   ],
   "source": [
    "weight_path = \"./model/face_recognition.pt\"\n",
    "device = torch.device(\"mps\")\n",
    "model = iresnet50().to(device)\n",
    "model.load_state_dict(torch.load(weight_path, map_location = device, weights_only=True))\n",
    "model.eval()\n",
    "print(\"Model Loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"카메라가 열리지 않습니다.\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_detection = face_detector(frame, 2)\n",
    "        \n",
    "        if len(face_detection) > 0:\n",
    "            f = face_detection[0]\n",
    "            faceAligned = fa.align(frame, gray, f)\n",
    "            known_embed = face_embedding(model, faceAligned, 112)\n",
    "            cursor.execute(f\"INSERT INTO faceEmbeddings (userId, embedding) VALUES(1, {known_embed})\")\n",
    "            break\n",
    "\n",
    "        cv2.imshow('frame', gray)\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"카메라가 열리지 않습니다.\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_detection = face_detector(frame, 2)\n",
    "        \n",
    "        if len(face_detection) > 0:\n",
    "            f = face_detection[0]\n",
    "            faceAligned = fa.align(frame, gray, f)\n",
    "            known_embed = face_embedding(model, faceAligned, 112)\n",
    "            cursor.execute(f\"SELECT count(*) as cnt FROM faceEmbeddings WHERE embedding = {known_embed}\")\n",
    "            \n",
    "            result = cursor.fetchone()\n",
    "\n",
    "            if result[0] > 0:\n",
    "                print(\"인증 성공\")\n",
    "            else:\n",
    "                print(\"인증 실패\")\n",
    "\n",
    "        cv2.imshow('frame', gray)\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SmartHome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
